The authors of the **Paddy Rice Imagery Dataset for Panicle Segmentation** recognize the critical role of precise *panicle* identification. They acknowledge the potential of deep learning methods, rooted in high-spatial-resolution images, for achieving both high throughput and accuracy in panicle segmentation. However, they highlight the considerable challenges posed by the need for costly annotations to train robust deep-learning models. Furthermore, the scarcity of public datasets specifically tailored for rice-panicle phenotyping presents a substantial hurdle. In response, the authors propose a semi-supervised approach to deep learning model training, designed to facilitate dataset annotation and refinement. Their approach involves training the model on limited annotations while enabling it to autonomously localize more positive samples within the dataset, thus reducing the need for extensive manual intervention. Remarkably, this dataset refinement process results in a 40.6% increase in the number of annotations.

The authors emphasize the broader context of their work within the realms of global population growth and climate change. They stress the significance of accurate panicle segmentation in understanding grain yield, growth periods, nutrition assessment, and disease detection in rice crops. They underscore the limitations of traditional panicle observation, which relies heavily on manual labor, tends to be labor-intensive, and yields results subject to sampling limitations. Consequently, the authors advocate for automated and precise panicle detection methods, aligning with the goals of smart agriculture, where efficiency, accuracy, reliability, and cost-effectiveness are paramount.

The data collection was conducted in August 2018, at the experimental paddy field of Hokkaido University, Sapporo, Japan. The white dashed line indicates the flight route. There are two rice species, Kitaake and Kokusyokuto-2. The cultivation densities are around 11.46 ~ 16.18 plants/m2. The authors used a commercial UAV to capture the rice field images.

<img src="https://github.com/dataset-ninja/gland-segmentation/assets/78355358/cf2b940c-99f2-4c67-aa09-78ff967643d9" alt="image" width="800">


|     FOV     | Aperture | Gimbal |  Resolution  | Velocity (m/s) | Altitude (m) | GSD (cm/px) |
| :------------: | :--------: | :------: | :------------: | :--------------: | :------------: | :-----------: |
| 78.8 (26 mm) |  f/2.2  |  −90  | 4096 × 2160 |      0.28      |     1.2     |    0.04    |

<span style="font-size: smaller; font-style: italic;">Configurations of UAV and the camera.</span>

Furthermore, the authors share their strategy for creating a basic dataset, where they manually annotate panicle boundaries using the [Labelme](https://github.com/wkentaro/labelme) tool. They analyze the annotations' characteristics across different stages of rice growth (heading stage, flowering stage and ripening stage) and emphasize the importance of images captured on August 12 as being particularly informative for panicle identification. Their basic dataset comprises 400 images with a total of 36,089 annotations*. 

The authors elucidate the dataset refinement process, which involves training an instance segmentation model (Mask R-CNN) using manual annotations and then applying this model to refine the entire dataset. They describe the process of scanning the full-resolution images using a sliding window approach and generating a confidence map based on model predictions. After applying threshold and morphology filtering methods, they obtain the refined dataset, which includes both manually labeled annotations and new annotations generated by the model.

<img src="https://github.com/dataset-ninja/gland-segmentation/assets/78355358/984308d4-c2ec-40f7-b5fe-7cedf175b06f" alt="image" width="800">

Finally, the authors highlight the importance of splitting the refined dataset into training, validation, and testing subsets for machine learning research. They emphasize the need to balance the size of receptive fields for annotation completeness and GPU memory constraints. The authors provide insights into the characteristics of these subsets and underscore the challenges related to receptive field size in capturing complete panicle annotations.

<i>*It differs from the actual number of instances</i>
